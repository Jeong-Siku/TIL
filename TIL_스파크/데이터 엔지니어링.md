# 데이터 엔지니어링

> 6.1

<br>

## `ETL`(Extract, Transform, Load)

> 비즈니스에 맞게 원하는 데이터를 형식 지정하는 것
>
> - 서비스 중심
>   > 데이터의 형식이 거의 지정되어 있고, 변동이 없는 환경에서의 데이터 파이프라인을 뜻한다.

- Extract = 추출(수집)

  - 기존의 데이터베이스로부터 데이터를 가져오는 행위

- Transform = 변형

  - 추출된 데이터를 미리 정해 놓은 스키마에 맞게 데이터를 변환

- Load = 적재(저장)
  - 변환이 완료된 데이터를 원하는 스키마에 INSERT하는 과정

<br>

## ELT로 변화

> 빅데이터 시대에 따라 데이터 형태가 변화됨.
> 이에 따라 변화
>
> - 데이터 중심

<br>

데이터 추출 -> 일단 저장(적재) -> 쓰임새에 따라 변환
Spark를 통해 데이터 추출 -> Spark나 Flink 등을 이용해서 어느정도 정리 후 저장 -> 어플리케이션 또는 분석 툴에서 이용가능하도록 변환

사용되는 플랫폼:  
Hadoop -> DAtabricks  
EMR

과거 데이터는 용량을 이미 알고 있음
미래에 데이터는 볼륨을 알 수 없음 (예측)

소스 + 수집및 변환 + 저장 => 데이터 플랫폼 엔지니어 파트
과거 + 예측 => 전처리->EDA->예측(모델링) => DE DA DS 파트

<br>

---

<br>

## Batch Processing

> 일괄 처리  
> 많은 양의 데이터를 정해진 시간에 한꺼번에 처리하는 것

![](20230602141955.png)
<br>

언제사용?

- 실시간성 필요 x
- 데이터를 한꺼번에 처리할 수 있을 때 (정해진 시간에)
- 무거운 처리할 때 (머신 러닝 학습)

<br>

## Stream Processing

> 실시간 데이터 처리

- 뷸규칙적으로 데이터가 들어오는 환경 -> 대기라는 환경이 필요
- event ≈ DATA ≈ Message : ~할 때

<br>

언제 사용?

- 실시간성 보장
- 데이터가 여러 소스로부터 들어올 때
- 데이터가 가끔 들어오거나 지속적으로 들어올 때
- 가벼운 데이터를 처리(Rule-based)

<br>

## 마이크로 배치(Micro-Batch)

> 준실시간성  
> 배치 프로세싱을 잘게 쪼개서 스트리밍을 따라한 것

<br>

---

<br>
 
 ## 분산 데이터 아키텍처

<br>

### MPP(Massively Parallel Processing)

- 대용량 병렬 처리 개념의 등장

### HDFS(Hadoop Distributed File System)

- 대용량 병렬 처리를 저렴한 비용으로 수행 가능
- Map-Reduce와 같은 역할을 했음

GFS

- 클러스터 구축
- 여러대의 컴퓨터를 묶는다.  
  -> Hadoop 등장

HDFS

- 파일 시스템

Map Reduce

- 연산 엔진

Yarn

- 리소스 관리
- 클러스터 관리

HDFS + Map Reduce => 코어 시스템

데이터와 장비관리

- heartbeat, balancing, replication

Master-Worker 구조

파일을 분할했기 때문에 처리해야할 데이터가 적어져서 Map Reduce를 이용해 빠르게 집계

- 네트워크 통신 없이 내부적인 처리만으로 데이터를 처리 가능. 속도 향상

### Map-Reduce

- Mapping : 데이터를 목적에 맞게 처리가능하도록 펼쳐놓는 것
- shuffling : 네트워크 통신이 일어난다.
  - Partitioning 과정이 필요하다.
  - 최대한 셔플링이 일어나지 않도록 할 것.
  - 최대한 비슷한 것들끼리 묶도록 할 것.
  - Map-Reduce를 준비할 때 유의할 것  
    \*\*Hashing
- Reduce : 집계에 의한 데이터 감소. 압축하는 과정

map-reduce는 자바를 이용함. map-reduce는 HIVE와 SPARK로 대체
SQL로 HIVE를 통해 분석가능

hadoop는 하드디스크
spark는 ssd

## spark

데이터를 쪼개서 처리

- 대용량의 데이터를 여러 노드(컴퓨터)의 메모리에서 동시에 처리
- in-memory 고속 연산

Driver Program-SparkContext : Master, Task 작성

- 드라이버 프로그램은 worker에서 실행됨
- 마스터는 프로그램을 전달
- worker의 executor가 프로그램을 실행

Cluster Manager : 스케쥴링 담당

Worker Node : 연산 수행

master에서 설치된 프로그램들은 자동으로 worker에 동기화된다. master와 worker는 역할을 바꿀 수 있다.

pandas의 numpy는 병렬처리.  
병렬처리는 cpu하나가 여러작업을 동시에 하는 것
분산처리는 데이터를 물리적으로 쪼개서 cpu하나가 처리하는 것

---

IP 주소 : 인터넷 상 computer 주소

BindIP : 서버가 실행될 IP주소 -> 0.0.0.0 : 어디에서든 접속이 가능!

- 인트라넷이 아니라면 주로 이렇게 설정

## RDD(Resilient Distributed Dataset)

> 탄력적인!  
> 스파크에서 사용하는 데이터의 최소단위  
> numpy와 같이 최소 단위

<br>

RDD-> SparkDF,SparkSQL을 통해 데이터를 다룬다. EDA처리

실무에서는 RDD를 쓰지는 않음. 특징을 잘 알아둘 것!

RDD는 분산되어 worker들의 메모리 안쪽에 위치한다.

- ★★변경이 불가능하다! immutable. DataFrame의 inplace와 같은 기능이 없다.

데이터 추상화

- HDFS, 데이터는 여러 클러스터에 흩어져 있지만 하나의 파일인 것처럼 사용이 가능하다.

RDD가 필요한 이유!

- 장애 발생 시, 불변성을 지닌 데이터를 통해 복원이 가능!

RDD는 변환을 거치면 기존의 RDD가 변경되는 것이 아닌, 변경된 새로운 RDD가 만들어진다.

- DAG
- RDD에 변환이 수행될때 마다 기록된다!
- 비 순환 그래프.
- 탄력적

Type Safe 특징

- 코드를 작성하고 컴파일 도중에 데이터의 타입을 판별할 수 있어 문제를 일찍 발견 할 수 있다.

다양한 데이터 구조 지원

- 비정형(텍스트), 정형(테이블) 모두 가능
- 이미지는 일반적으로 제외할 것

★★★ `Lazy Evaluation`

> 게으른 연산

- 결과가 필요할 떄까지 연산을 하지않고 기다린다.
- 변환 작업을 등록만 하고 수행은 하지않는다.
- 트랜스포메이션은 변환과정이며 Action을 수행할 때까지 실행되지 않는다.

  spark 연산 = Transformations + Actions

<-> _Eager Execution_

- ex) pandas

---

## 병렬처리와 분산처리

Data-Parallel(병렬)
task : 작업 내용(함수)

- 스칼라와 파이썬은 함수형 프로그래밍이기 떄문에 쓰인다. callback으로 함수를 파라미터로 쓸 수 있음.

코드조각(task)들이 worker로 넘어간다.

쓰레드와 프로세스의 차이

- 프로세스 : 프로그램이 실행되면 프로세스가 된다.
  - 프로그램은 DISK에 설치된다.
  - 프로그램을 실행하면 cpu가 디스크에서 찾고 해당 프로그램을 램에 적재한다. 적재하는 과정을 process
- 쓰레드 : 하나의 process에서 -> Task ->task -> 일괄처리방식
- cpu가 처리할 수 있는 속도 : HZ
- cpu는 쓰레드를 왔다갔다하면서 처리한다.
- 쓰레드가 하나밖에 없는 프로그램이면 그 자체가 프로세스

최적화와 연관  
-> 분산처리 + 병렬처리의 연산과정
-> 노드 간 통신 등 통신속도를 신경써야한다.

분산된 환경에서도 병렬처리 가능

어떤 작업을 어떻게 코드로 나타내는가에 따라서 속도가 달라진다.
-> 통신량을 줄이도록
-> filter는 각각의 노드에서 실행된다.
-> reduceByKey는 통신을 통해 데이터를 불러온다.

## Key-Value RDD

- 딕셔너리와 유사 (key, value)
- Pairs RDD
- 이전까지는 single-value RDD
- key를 기준으로 고차원적인 연산 가능 : Group By!
- 다양한 집계 연산 가능!

Reduction 연산

- 키값을 기준으로 데이터를 묶어서 처리하기 때문에 데이터를 줄여준다.

lambda a,b : a+b

- a는 누적 값
- b는 새로운 값

## Transformation

Narrow Transformation + Wide Transformation

Narrow Transformation

- 다른 열 및 파티션의 데이터를 사용할 필요가 없다.

Wide Transformation

- 셔플링을 통해 다른 파티션의 데이터가 들어갈 수 있다.

## Cache & Persist

> 모두 메모리에 데이터를 올려두는 작업을 한다.  
> 주로 Cache를 사용한다.  
> 메모리가 부족할 수 있으니 작은 RDD에서만 사용할 것

Lazy Execution의 유리함

- 메모리를 최대한 활용
- 데이터를 다루는 task는 반복되는 경우가 많다.

반복적인 데이터 작업에 의한 비효율
Task -> Disk -> Task -> Disk ...
-> 디스크에 계속 데이터를 저장하고 불러오는 방식은 속도를 저하시킵니다.
=> 메모리 내에서 Task끼리 데이터를 교환한다면 훨씬 빠를 것 같다! ex) 머신러닝
->cache와 persist를 이용하여 메모리내에 데이터를 저장

SER을 통해 직렬화 - 2진화되면서 메모리 절약

# Chapter 04. Spark SQL, DataFrame, Dataset

1. 데이터를 합치고 추출하는 방법

- 셔플링이 적게 일어나는 것을 중점으로!
  - join과 filter의 순서를 바탕으로
- 하지만 이런 고민은 개발자의 경험에 따라 성능 차이를 만든다.

  - 데이터의 구조화를 잘시켜서 자동으로 최적화가 가능하도록 한다!

- RDD는 데이터의 구조를 모르기 때문에 개발자에게 의존
- Structured Data는 어떤 Task를 수행할 것인지 정의

Spark DataFrame 만들기

### RDD

from pyspark import SparkConf, SparkContext
conf = SparkConf().setMaster('local').setAppName('spark_sql_basic')
sc = SparkContext(conf=conf)

### spark DF 만들기

from pyspark.sql import SparkSession

1. spark 객체 만들기
   spark = SparkSession.builder.master('local').appName("spark-sql").getOrCreate() # spark 이름이 바뀌면 안된다.
2. df 만들기
   2-1. RDD를 이용해서
   df= spark.createDataFrame(data=movies, schema = movie_schema)
   RDD 객체를 가져와서 만들기
   2-2. 파일을 불러와서
   filepath="/home/ubuntu/working/spark-examples/data/titanic_train.csv"
   titanic_sdf = spark.read.csv(filepath, inferSchema=True,header=True) # header = 'infer' 을 통해 자동 설정 가능

3. SQL 쿼리 사용을 위한 임시 VIEW 만들기 -> table이 되는 것
   df.createOrReplaceTempView("movies")

3-1. 쿼리 사용하기
query='''
'''
spark.sql(query).show()

3-2. 데이터프레임 API
df를 바탕으로 활용
df.select("\*").collect()

## Spark Backend

Catalyst : Query 계획 최적화
Tungsten : 메모리와 CPU의 효율을 최적화 해주는 엔진

---

MLlib

> 6.13
> Spark ML

인터프리터 spark_env로 옮길 것
spark-submit 15-MovieRecommend.py

1. python 실행
   - Test 모드, Notebook
     - EDA
     - 빠른 결과
2. Spark-submit 실행

- 실행모드
- 장애 대응

---

1. Hadoop 구성
   - NameNode(Standby) - Journal - Name Node(Active - S-Name Node
   - Worker(Date Node) - Worker(Date Node) - Worker(Date Node) .....

하둡 데이터 노드와 스파크 워커는 항상 같은 곳에 위치시킬 것

- 네트워크 통신이 최대한 덜 반복되도록

Spark 기초 개념에서 참고할 것

---

# 카프카

큐잉

- Queue에 메세지 담고 처리
- Queue : FIFO 방식 자료구조
- Message : 발생되는 중인 데이터, 앞으로 수집할
- 배치 : 이미 발생되어 수집된 데이터

Message Queue

Producer : 메세지를 생산하는 주체
Consumer : 메세지를 소비
Topic : 메시지가 저장되는 장소를 `논리적으로 표현하는 개념`. In-Memory
Broker : 카프카 서버. Bootstrap Server. Producer와 Consumer가 접속하여 topic을 가져온다. 이중화
파티션 : topic이 실제 디스크에 물리적으로 저장되는 기준. 시간 순서를 나타내기 위해 offset이라는 순번을 가진다.

컨슈머 그룹

클러스터 구성

- 여러 대의 서버가 하나의 토픽을 서빙한다.
- 고가용성 : 에러가 나도 계속 진행할 수 있다.

Zookeeper

KIP500

- 쥬키퍼를 카프카랑 분리하려는 프로젝트
- 오픈소스 , Confluent

Avro : 타입이 있는 JSON 형식

토픽이 중요하다. 카프카 파티션은 여러 브로커에 걸쳐서 생성된다.

Round Robin

- 원형으로 돌아가면서 분배. 한바퀴돌면 다시 처음부터

파티션 리더

- 복제된 파티션은 프로듀서와 컨슈머에게 정보를 보내지 않는다. 백업용

컨슈머 그룹

- 각 컨슈머 그룹은 각자 다른 기능을 수행 가능

프로듀서나 컨슈머가 여러개여도 파티션이 한개면 하나의 컨슈머에서만 정보가 출력된다.
