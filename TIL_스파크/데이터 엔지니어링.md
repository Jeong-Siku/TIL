# 데이터 엔지니어링

> 6.1

<br>

## ETL(Extract, Transform, Load)

> 비즈니스에 맞게 원하는 데이터를 형식 지정하는 것
>
> - 서비스 중심
>   > 데이터의 형식이 거의 지정되어 있고, 변동이 없는 환경에서의 데이터 파이프라인을 뜻한다.

- Extract = 추출(수집)

  - 기존의 데이터베이스로부터 데이터를 가져오는 행위

- Transform = 변형

  - 추출된 데이터를 미리 정해 놓은 스키마에 맞게 데이터를 변환

- Load = 적재(저장)
  - 변환이 완료된 데이터를 원하는 스키마에 INSERT하는 과정

<br>

## ELT로 변화

> 빅데이터 시대에 따라 데이터 형태가 변화됨.
> 이에 따라 변화
>
> - 데이터 중심

<br>

데이터 추출 -> 일단 저장(적재) -> 쓰임새에 따라 변환
Spark를 통해 데이터 추출 -> Spark나 Flink 등을 이용해서 어느정도 정리 후 저장 -> 어플리케이션 또는 분석 툴에서 이용가능하도록 변환

사용되는 플랫폼:  
Hadoop -> DAtabricks  
EMR

과거 데이터는 용량을 이미 알고 있음
미래에 데이터는 볼륨을 알 수 없음 (예측)

소스 + 수집및 변환 + 저장 => 데이터 플랫폼 엔지니어 파트
과거 + 예측 => 전처리->EDA->예측(모델링) => DE DA DS 파트

<br>

---

<br>

## Batch Processing

> 일괄 처리  
> 많은 양의 데이터를 정해진 시간에 한꺼번에 처리하는 것

<br>

언제사용?

- 실시간성 필요 x
- 데이터를 한꺼번에 처리할 수 있을 때 (정해진 시간에)
- 무거운 처리할 때 (머신 러닝 학습)

<br>

## Stream Processing

> 실시간 데이터 처리

- 뷸규칙적으로 데이터가 들어오는 환경 -> 대기라는 환경이 필요
- event ≈ DATA ≈ Message : ~할 때

<br>

언제 사용?

- 실시간성 보장
- 데이터가 여러 소스로부터 들어올 때
- 데이터가 가끔 들어오거나 지속적으로 들어올 때
- 가벼운 데이터를 처리(Rule-based)

<br>

## 마이크로 배치(Micro-Batch)

> 준실시간성  
> 배치 프로세싱을 잘게 쪼개서 스트리밍을 따라한 것

<br>

---

<br>
 
 ## 분산 데이터 아키텍처

<br>

### MPP(Massively Parallel Processing)

- 대용량 병렬 처리 개념의 등장

### HDFS(Hadoop Distributed File System)

- 대용량 병렬 처리를 저렴한 비용으로 수행 가능
- Map-Reduce와 같은 역할을 했음

GFS

- 클러스터 구축
- 여러대의 컴퓨터를 묶는다.  
  -> Hadoop 등장

HDFS

- 파일 시스템

Map Reduce

- 연산 엔진

Yarn

- 리소스 관리
- 클러스터 관리

HDFS + Map Reduce => 코어 시스템

데이터와 장비관리

- heartbeat, balancing, replication

Master-Worker 구조

파일을 분할했기 때문에 처리해야할 데이터가 적어져서 Map Reduce를 이용해 빠르게 집계

- 네트워크 통신 없이 내부적인 처리만으로 데이터를 처리 가능. 속도 향상

### Map-Reduce

- Mapping : 데이터를 목적에 맞게 처리가능하도록 펼쳐놓는 것
- shuffling : 네트워크 통신이 일어난다.
  - Partitioning 과정이 필요하다.
  - 최대한 셔플링이 일어나지 않도록 할 것.
  - 최대한 비슷한 것들끼리 묶도록 할 것.
  - Map-Reduce를 준비할 때 유의할 것  
    \*\*Hashing
- Reduce : 집계에 의한 데이터 감소. 압축하는 과정

map-reduce는 자바를 이용함. map-reduce는 HIVE와 SPARK로 대체
SQL로 HIVE를 통해 분석가능

hadoop는 하드디스크
spark는 ssd

## spark

데이터를 쪼개서 처리

- 대용량의 데이터를 여러 노드(컴퓨터)의 메모리에서 동시에 처리
- in-memory 고속 연산

Driver Program-SparkContext : Master, Task 작성

- 드라이버 프로그램은 worker에서 실행됨
- 마스터는 프로그램을 전달
- worker의 executor가 프로그램을 실행

Cluster Manager : 스케쥴링 담당

Worker Node : 연산 수행

master에서 설치된 프로그램들은 자동으로 worker에 동기화된다. master와 worker는 역할을 바꿀 수 있다.

pandas의 numpy는 병렬처리.  
병렬처리는 cpu하나가 여러작업을 동시에 하는 것
분산처리는 데이터를 물리적으로 쪼개서 cpu하나가 처리하는 것

★★Lazy Evaluation

---

## RDD
